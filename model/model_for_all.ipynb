{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eed2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "Cluster 0: 100%|██████████| 875/875 [03:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "Cluster 1: 100%|██████████| 854/854 [01:35<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 1. Load and preprocess full dataset ===\n",
    "df = pd.read_csv(\"synthetic_trashcan_fill_levels2.csv\")\n",
    "time_series = df.drop(columns=[\"edgeID\", \"trashcanID\"])\n",
    "edge_ids = df[\"edgeID\"].values\n",
    "\n",
    "# Downsample: average every 4 days (200 → 50)\n",
    "reshaped = time_series.to_numpy().reshape((len(df), 50, 4))\n",
    "downsampled = reshaped.mean(axis=2)\n",
    "\n",
    "# Normalize for clustering\n",
    "scaler = StandardScaler()\n",
    "normalized = scaler.fit_transform(downsampled)\n",
    "\n",
    "# === 2. Clustering ===\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(normalized)\n",
    "df[\"cluster\"] = clusters\n",
    "\n",
    "# === 3. Sequence prep function ===\n",
    "def create_sequences(series, window_size=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === 4. Train & Predict for each cluster ===\n",
    "selection_dict = {}\n",
    "for cluster_id in range(4):\n",
    "    print(f\"Processing Cluster {cluster_id}...\")\n",
    "    \n",
    "    # Filter data for cluster\n",
    "    cluster_mask = df[\"cluster\"] == cluster_id\n",
    "    cluster_series = time_series[cluster_mask].to_numpy()\n",
    "    cluster_edge_ids = df[\"edgeID\"][cluster_mask].values\n",
    "    \n",
    "    # Normalize per trashcan\n",
    "    scaler_lstm = StandardScaler()\n",
    "    norm_cluster = scaler_lstm.fit_transform(cluster_series)\n",
    "    \n",
    "    # LSTM inputs\n",
    "    # Create sequences per trashcan\n",
    "    X_all, y_all = [], []\n",
    "    for series in norm_cluster:\n",
    "        X, y = create_sequences(series)\n",
    "        X_all.extend(X)\n",
    "        y_all.extend(y)\n",
    "    X_all = np.array(X_all).reshape(-1, 10, 1)\n",
    "    y_all = np.array(y_all)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "    # LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(X_train.shape[1], 1)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # === Predict for each trashcan ===\n",
    "    for i, series in tqdm(enumerate(norm_cluster), total=len(norm_cluster), desc=f\"Cluster {cluster_id}\"):\n",
    "        edge_id = cluster_edge_ids[i]\n",
    "        actual_latest = series[-1]\n",
    "\n",
    "        # Predict next day's fill level\n",
    "        input_seq = series[-10:].reshape((1, 10, 1))\n",
    "        predicted_next = model.predict(input_seq, verbose=0)[0][0]\n",
    "\n",
    "        # Unnormalize both predicted and actual (only the last day)\n",
    "        predicted_real = predicted_next * scaler_lstm.scale_[-1] + scaler_lstm.mean_[-1]\n",
    "        actual_real = actual_latest * scaler_lstm.scale_[-1] + scaler_lstm.mean_[-1]\n",
    "\n",
    "        # Threshold-based decision\n",
    "        if actual_real >= 0.8:\n",
    "            selection = 2\n",
    "        elif predicted_real >= 0.8:\n",
    "            selection = 1\n",
    "        else:\n",
    "            selection = 0\n",
    "\n",
    "        selection_dict[edge_id] = selection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
